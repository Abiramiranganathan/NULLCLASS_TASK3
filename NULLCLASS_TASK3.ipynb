{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca95733-18ef-4514-9ede-246c07ffb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "Id                         0\n",
      "ProductId                  0\n",
      "UserId                     0\n",
      "ProfileName               26\n",
      "HelpfulnessNumerator       0\n",
      "HelpfulnessDenominator     0\n",
      "Score                      0\n",
      "Time                       0\n",
      "Summary                   27\n",
      "Text                       0\n",
      "dtype: int64\n",
      "sentiment\n",
      "positive    443777\n",
      "negative     82037\n",
      "neutral      42640\n",
      "Name: count, dtype: int64\n",
      "                                          clean_text sentiment\n",
      "0  i have bought several of the vitality canned d...  positive\n",
      "1  product arrived labeled as jumbo salted peanut...  negative\n",
      "2  this is a confection that has been around a fe...  positive\n",
      "3  if you are looking for the secret ingredient i...  negative\n",
      "4  great taffy at a great price there was a wide ...  positive\n",
      "✅ Cleaned dataset saved to: C:\\Users\\abira\\OneDrive\\Desktop\\NULL CLASS\\Reviews_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "#  Load CSV into DataFrame\n",
    "csv_path = r\"C:\\Users\\abira\\OneDrive\\Desktop\\NULL CLASS\\Reviews.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "#  Quick look at data\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "#  Check for missing values and drop if any\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Text', 'Score'])  # keep only rows with text and score\n",
    "\n",
    "#  Create sentiment labels based on 'Score' column\n",
    "def get_sentiment(score):\n",
    "    if score <= 2:\n",
    "        return 'negative'\n",
    "    elif score == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "df['sentiment'] = df['Score'].apply(get_sentiment)\n",
    "\n",
    "#  View distribution of sentiments\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "#  Basic text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "print(df[['clean_text', 'sentiment']].head())\n",
    "\n",
    "# Save cleaned dataset in same folder as original file\n",
    "output_path = os.path.join(\n",
    "    os.path.dirname(csv_path),\n",
    "    \"Reviews_cleaned.csv\"\n",
    ")\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Cleaned dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47f5464-3110-420b-b9d4-6cb346b43dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.8702271947647571\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.69      0.71     16407\n",
      "     neutral       0.53      0.22      0.31      8528\n",
      "    positive       0.90      0.97      0.93     88756\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.72      0.62      0.65    113691\n",
      "weighted avg       0.85      0.87      0.86    113691\n",
      "\n",
      " Model and vectorizer saved for chatbot use.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "#  Load the cleaned dataset\n",
    "csv_path = r\"C:\\Users\\abira\\OneDrive\\Desktop\\NULL CLASS\\Reviews_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Remove NaN values in clean_text\n",
    "df['clean_text'] = df['clean_text'].fillna(\"\")\n",
    "\n",
    "#  Split data into training and testing sets\n",
    "X = df['clean_text']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#  Predict before evaluating\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "#  Evaluate model\n",
    "print(\" Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#  Save the model and vectorizer for chatbot integration\n",
    "joblib.dump(model, r\"C:\\Users\\abira\\OneDrive\\Desktop\\NULL CLASS\\sentiment_model.pkl\")\n",
    "joblib.dump(vectorizer, r\"C:\\Users\\abira\\OneDrive\\Desktop\\NULL CLASS\\tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\" Model and vectorizer saved for chatbot use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e4eab3-c6b9-4375-82f4-43d499348872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Amazon Fine Food Review Chatbot (type 'exit' to quit)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:   I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Sentiment is positive 😊\n",
      "Bot Reply: Thank you so much for your kind words! We’re thrilled you enjoyed it and can’t wait to serve you again.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:   product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Sentiment is negative 😞\n",
      "Bot Reply: We’re sorry your experience wasn’t as expected. Your feedback helps us improve, and we’ll work to make it right next time.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  this seems a little more wholesome than some of the supermarket brands but it is somewhat mushy and doesnt have quite as much flavor either it didnt pass muster with my kids so i probably wont buy it again\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Sentiment is neutral 😐\n",
      "Bot Reply: Thank you for sharing your thoughts. We appreciate your suggestions and will use them to make your next experience even better.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye! 👋\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load saved model and vectorizer\n",
    "model = joblib.load(r\"C:\\\\Users\\\\abira\\\\OneDrive\\\\Desktop\\\\NULL CLASS\\\\sentiment_model.pkl\")\n",
    "vectorizer = joblib.load(r\"C:\\\\Users\\\\abira\\\\OneDrive\\\\Desktop\\\\NULL CLASS\\\\tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"\\n💬 Amazon Fine Food Review Chatbot (type 'exit' to quit)\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Exit condition\n",
    "    if user_input.lower().strip() == \"exit\":\n",
    "        print(\"Bot: Goodbye! 👋\")\n",
    "        break\n",
    "\n",
    "    # Transform input\n",
    "    user_tfidf = vectorizer.transform([user_input])\n",
    "\n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(user_tfidf)[0].lower()\n",
    "\n",
    "    # Respond based on sentiment\n",
    "    if prediction == \"positive\":\n",
    "        print(\"Bot: Sentiment is positive 😊\")\n",
    "        print(\"Bot Reply: Thank you so much for your kind words! We’re thrilled you enjoyed it and can’t wait to serve you again.\")\n",
    "    elif prediction == \"negative\":\n",
    "        print(\"Bot: Sentiment is negative 😞\")\n",
    "        print(\"Bot Reply: We’re sorry your experience wasn’t as expected. Your feedback helps us improve, and we’ll work to make it right next time.\")\n",
    "    else:\n",
    "        print(\"Bot: Sentiment is neutral 😐\")\n",
    "        print(\"Bot Reply: Thank you for sharing your thoughts. We appreciate your suggestions and will use them to make your next experience even better.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955a9c5-bef5-4919-a62d-734de92f6ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
